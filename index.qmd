---
title: Moju Kapu モジュカプ
subtitle: How `mirai` and `crew` Are Powering the Next Generation of Parallel Computing in R
author: Charlie Gao and Will Landau
institute: Hibiki AI Limited, Eli Lilly and Company
date: July 9, 2024
format:
    revealjs:
        theme:
            - custom.scss
        incremental: true
        footer: "slides available at https://shikokuchuo.net/user2024-conference"
        embed-resources: true
        slide-number: true
editor:
    render-on-save: true
---

## {.center}

<style>
h1 {
  font-size: 1.6em !important;
}
h2 {
  font-size: 1.4em !important;
}
</style>

<img src="images/mojukapu.png" />

`moju-kapu` （モジュカプ） is shorthand for `modular encapsulation` （モジュラーカプセル化）

. . .

::: {.nonincremental}
- Balance
- Effective stand-alone tools < > entire integrated systems

- Natural limits of a package
- Interfaces for developers as well as end-users
- Layered engineering approach
:::

## The Back Story

- Why targets needed `crew`?

- What was missing for `crew` to become feasible?

- How `mirai` provided the solution.

## The Back Story (Cont'd)

::: {.nonincremental}

- Feb 2023 - CG/WL collaboration starts

- Mar 2023 - initial `mirai` backend for `crew`

- Apr 2023 - `targets` 1.0.0 with `crew` integration

- Jul 2023 - TLS lands in `mirai` and `crew`

- Oct 2023 - `mirai` implements parallel backend for R

- Dec 2023 - `mirai` serialization initial support for `torch`

- Mar 2024 - `mirai` serialization supports ADBC database hosting

- May 2024 - `mirai` 1.0.0 - implements next-gen promises
:::

# mirai

## {.center}
::: {.nonincremental}

みらい &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; / mI ˈ ra ˈ i: /


n. future
:::

Minimalist Async Evaluation Framework for R

## {.center}

mirai - Designed for Production

. . .

:::: {.columns}

::: {.column width="50%"}
::: {.nonincremental}
1. High Performance
2. Simple and Robust
3. Massively Scalable

:::
:::

::: {.column width="50%"}
::: {.nonincremental}
- 100x faster
- WYSIWYG concept
- one million promises

:::
:::
::::

## External Encapsulation

[<img alt="R parallel" src="https://www.r-project.org/logo/Rlogo.png" width="40" />](https://shikokuchuo.net/mirai/articles/parallel.html) &nbsp; An alternative communications backend for R, implementing a request by R-Core at R Project Sprint 2023

[<img alt="promises" src="https://docs.posit.co/images/posit-ball.png" width="40" />](https://shikokuchuo.net/mirai/articles/promises.html) &nbsp; Next generation completely event-driven promises

[<img alt="Shiny" src="https://github.com/rstudio/shiny/raw/main/man/figures/logo.png" width="40" />](https://shikokuchuo.net/mirai/articles/shiny.html) &nbsp; Asynchronous parallel / distributed backend

[<img alt="Plumber" src="https://rstudio.github.io/cheatsheets/html/images/logo-plumber.png" width="40" />](https://shikokuchuo.net/mirai/articles/plumber.html) &nbsp; Asynchronous parallel / distributed backend

[<img alt="Arrow" src="https://arrow.apache.org/img/arrow-logo_hex_black-txt_white-bg.png" width="40" />](https://shikokuchuo.net/mirai/articles/databases.html) &nbsp; Host ADBC database connections in daemon processes

[<img alt="torch" src="https://torch.mlverse.org/css/images/hex/torch.png" width="40" />](https://shikokuchuo.net/mirai/articles/torch.html) &nbsp; Seamless cross-process use of Torch tensors and models

# crew

---

## Re-encapsulating `mirai`

<center>
<img src="./images/crew.png" width=400>
</center>

---

## Why `crew`?

<center>
<img src="./images/crew-package-row.png" width=700>
</center>

<ul style="font-size: 30px">
  <li>Extends <code>mirai</code> to distributed computing environments.</li>
  <li>Centralized <code>R6</code> interface for tasks.</li>
  <li>Worker auto-scaling to respond fluctuating task loads.</li>
</ul>

## Moju Kapu in `crew`

.pull-left[

### Encapsulation

<center>
<img src="./images/crew-core.png" width=250>
</center>

* Uses `mirai` developer interface: `daemon()`, `nextget()`, `saisei()` etc.
* `R6` class system for the controller interface.

]

.pull-right[

### Modularity

<center>
<img src="./images/crew-plugins.png" width=250>
</center>

* Plugin system to launch parallel workers on different environments.
* Docs guide users to write their own plugins.
* Existing encapsulated plugins for SLURM, AWS Batch, etc.

]

## `R6` classes

| **Class** | **About** | 
|---|---|
| **Controller group** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | Interface for many controllers. |
| **Controller** | Central task interface. |
| **Tasks** | List of `mirai` task objects. | 
| **Client** | `mirai` TCP connection hub. |
| **Relay** | Coordinate `mirai` synchronization primitives. |
| **Launcher** | Launches workers. Subclasses for plugins. |
| **Async** | Parallelize worker launches. |

## `R6` object composition

<center>
<img src="./images/crew-design.png" width=400>
</center>

## `mirai` tasks, different interface

```{r, eval = FALSE}
# Start a controller.
library(crew)
controller <- crew_controller_local(
  workers = 2,
  seconds_idle = 10
)
controller$start()

# Submit tasks asynchronously.
controller$push(command = 1 + 1)
controller$push(command = sqrt(9))

# Wait for a task to finish.
controller$wait(mode = "one")

# Collect the result.
controller$pop()$result[[1]]
#> [1] 3
```

## Different plugin, different controller

```{r, eval = FALSE}
# Start an AWS Batch controller with many workers.
library(crew.aws.batch)
controller <- crew_controller_aws_batch(
  workers = 100,
  seconds_idle = 60,
  aws_batch_job_definition = "YOUR_JOB_DEFINITION",
  aws_batch_job_queue = "YOUR_JOB_QUEUE"
)
controller$start()

# Submit many tasks asynchronously.
controller$walk(
  command = your_expensive_task(data = object),
  iterate = list(object = list_of_objects),
  data = list(expensive_task = expensive_task)
)
```

## Write your own launcher plugin

* Tutorial to write plugins: <https://wlandau.github.io/crew/articles/plugins.html>

```{r, eval = FALSE}
custom_launcher_class <- R6::R6Class(
  classname = "custom_launcher_class",
  inherit = crew::crew_class_launcher,
  public = list(
    launch_worker = function(call, name, launcher, worker, instance) { #<<
      bin <- file.path(R.home("bin"), "R")
      processx::process$new(
        command = bin,
        args = c("-e", call),
        cleanup = FALSE
      )
    },
    terminate_worker = function(handle) { #<<
      handle$signal(crew::crew_terminate_signal())
    }
  )
)
```

## Controller wrapper

* Tutorial to write plugins: <https://wlandau.github.io/crew/articles/plugins.html>

```{r, eval = FALSE}
#' @title Create a controller with the custom launcher.
#' @export
#' @description Create an `R6` object to submit tasks and
#'   launch workers.
#' @inheritParams crew::crew_controller_local
crew_controller_custom <- function(...) {
  client <- crew::crew_client(...)
  launcher <- custom_launcher_class$new(...) #<<
  controller <- crew::crew_controller(client = client, launcher = launcher) #<<
  controller$validate()
  controller
}
```

# Appendix

# 1. mirai Design Concepts

## 100x Faster

Setup:

``` r
library(mirai)
library(future)

d <- daemons(1, dispatcher = FALSE)
plan("multisession", workers = 1)

m <- mirai(1)
collect_mirai(m)
#> [1] 1

f <- future(1)
value(f)
#> [1] 1
```

<sup>Created on 2024-05-27 with [reprex v2.1.0](https://reprex.tidyverse.org)</sup>

## 100x Faster (Cont'd)

Benchmarking:

``` r
bench::mark(mirai(1), future(1), relative = TRUE, check = FALSE)
#> # A tibble: 2 × 6
#>   expression   min median `itr/sec` mem_alloc `gc/sec`
#>   <bch:expr> <dbl>  <dbl>     <dbl>     <dbl>    <dbl>
#> 1 mirai(1)      1      1       74.6      1        1   
#> 2 future(1)   158.   113.       1        5.72     2.75

bench::mark(collect_mirai(m), value(f), relative = TRUE)
#> # A tibble: 2 × 6
#>   expression         min median `itr/sec` mem_alloc `gc/sec`
#>   <bch:expr>       <dbl>  <dbl>     <dbl>     <dbl>    <dbl>
#> 1 collect_mirai(m)   1      1        84.1       Inf      NaN
#> 2 value(f)          79.3   89.0       1         NaN      Inf
```

<sup>Created on 2024-05-27 with [reprex v2.1.0](https://reprex.tidyverse.org)</sup>

## WYSIWYG Concept

Production usage requires 'correctness' over 'convenience'.

Code behaves as written. There is no reliance on non-transparent static code analysis, which can result in inefficient behaviour, or even fail due to hidden global options:

``` r
library(mirai)
library(future)
df <- list(a = double(1e8), b = 1)

m <- mirai(2 * x, x = df$b)
m[]
#> [1] 2

f <- future(2 * df$b)
#> Error in getGlobalsAndPackages(expr, envir = envir, tweak =
#> tweakExpression, : The total size of the 1 globals exported for
#> future expression ('2 * df$b') is 762.94 MiB.. This exceeds the
#> maximum allowed size of 500.00 MiB (option 'future.globals.maxSize')
#> . There is one global: 'df' (762.94 MiB of class 'list')
```
## One Million Promises

``` r
library(mirai)
daemons(8, dispatcher = FALSE)
#> [1] 8

r <- 0
start <- Sys.time()
m <- mirai_map(1:1000000, \(x) x, .promise = \(x) r <<- r + x)
Sys.time() - start
#> Time difference of 6.42396 mins

later::run_now()
r
#> [1] 500000500000
```

<sup>Created on 2024-05-27 with [reprex v2.1.0](https://reprex.tidyverse.org) <br />
Running on an Intel i7 Gen 11 notebook with 16GB RAM.</sup>

