---
title: Moju Kapu モジュカプ
subtitle: How `mirai` and `crew` Are Powering the Next Generation of Parallel Computing in R
author: Charlie Gao and Will Landau
institute: Hibiki AI Limited, Eli Lilly and Company
date: July 9, 2024
format:
    revealjs:
        theme:
            - custom.scss
        incremental: true
        footer: "slides available at https://shikokuchuo.net/user2024-conference"
        embed-resources: true
        slide-number: true
editor:
    render-on-save: true
---

## {.center}

<style>
h1 {
  font-size: 1.6em !important;
}
h2 {
  font-size: 1.4em !important;
}
</style>

<img src="images/mojukapu.png" />

`moju-kapu` （モジュカプ） is shorthand for `modular encapsulation` （モジュラーカプセル化）

. . .

::: {.nonincremental}
- Effective stand-alone tools < > entire integrated systems
- Natural limits of a package
- Interfaces for developers as well as end-users
- Layered engineering approach
:::

# mirai

## {.center}
::: {.nonincremental}

<img alt="mirai logo" src="images/mirai.png" width="120" />
mirai - the / moju kapu /
:::

::: {.nonincremental}

* **Motivation**: production-grade parallel computing for R
* **Modularity**: interfaces with and enhances base R / Shiny etc.
* **Encapsulation**: developer interface for 3rd party launchers such as `crew`

:::

## mirai {.center}

Parallel & distributed computing for R

. . .

:::: {.columns}
::: {.column width="20%"}

<img alt="mirai logo" src="images/mirai.png" width="120" />

:::

::: {.column width="80%"}

The 新幹線 Shinkansen (bullet train)

<img alt="Shinkansen" src="images/shinkansen_fuji.jpg" width="800" />

:::
::::

##

<img alt="mirai logo" src="images/mirai.png" width="120" />
mirai - The Shinkansen of Parallel Computing

. . .

:::: {.columns}

::: {.column width="50%"}
::: {.nonincremental}
1. Fast

:::
:::

::: {.column width="50%"}
::: {.nonincremental}
- 100x faster

:::
:::
::::

. . .

:::: {.columns}
::: {.column width="50%"}
```r
future::value(future::future(1))
#> [1] 1
```
:::
::: {.column width="50%"}
```r
mirai::mirai(1)[]
#> [1] 1
```
:::
::::

. . .

:::: {.columns}
::: {.column width="50%"}

<img alt="Toy train" src="images/toy_train.jpg" height="300" />

:::
::: {.column width="50%"}

<img alt="Shinkansen" src="images/shinkansen.jpg" height="300" />

:::
::::

##

<img alt="mirai logo" src="images/mirai.png" width="120" />
mirai - The Shinkansen of Parallel Computing

:::: {.columns}

::: {.column width="50%"}
::: {.nonincremental}
1. Fast
2. Reliable

:::
:::

::: {.column width="50%"}
::: {.nonincremental}
- 100x faster
- WYSIWYG concept

:::
:::
::::

. . .

<img alt="headline" src="images/shinkansen_headline.png" width="800" />

##

<img alt="mirai logo" src="images/mirai.png" width="120" />
mirai - The Shinkansen of Parallel Computing

:::: {.columns}

::: {.column width="50%"}
::: {.nonincremental}
1. Fast
2. Reliable

:::
:::

::: {.column width="50%"}
::: {.nonincremental}
- 100x faster
- WYSIWYG concept

:::
:::
::::

```r
model$accuracy
#> [1] 0.95
```
. . .

```r
f <- future::future(model$accuracy)
```
. . .

<span style="color:#ff0000">
Error in getGlobalsAndPackages(expr, envir = envir, tweak = tweakExpression,  : 
  The total size of the 1 globals exported for future expression (‘model$accuracy’) is 762.94 MiB.. This exceeds the maximum allowed size of 500.00 MiB (option 'future.globals.maxSize'). There is one global: ‘model’ (762.94 MiB of class ‘list’)
</span>

##

<img alt="mirai logo" src="images/mirai.png" width="120" />
mirai - The Shinkansen of Parallel Computing

:::: {.columns}

::: {.column width="50%"}
::: {.nonincremental}
1. Fast
2. Reliable

:::
:::

::: {.column width="50%"}
::: {.nonincremental}
- 100x faster
- WYSIWYG concept

:::
:::
::::

```r
model$accuracy
#> [1] 0.95
```
. . .

```r
m <- mirai::mirai(x, x = model$accuracy)

```
. . .

```r
m[]
#> [1] 0.95
```

##

<img alt="mirai logo" src="images/mirai.png" width="120" />
mirai - The Shinkansen of Parallel Computing

:::: {.columns}

::: {.column width="50%"}
::: {.nonincremental}
1. Fast
2. Reliable
3. Scalable

:::
:::

::: {.column width="50%"}
::: {.nonincremental}
- 100x faster
- WYSIWYG concept
- one million promises

:::
:::
::::

. . .

:::: {.columns}

::: {.column width="50%"}
<img alt="tokyo metro" src="images/metro.png" width="400" />
:::

::: {.column width="50%"}
<img alt="shanghai maglev" src="images/maglev.webp" width="400" />
:::
::::

## Modularity: Interfaces with and Enhances

[<img alt="R parallel" src="https://www.r-project.org/logo/Rlogo.png" width="100" />](https://shikokuchuo.net/mirai/articles/parallel.html) &nbsp; An alternative communications backend for R

[<img alt="Shiny" src="https://github.com/rstudio/shiny/raw/main/man/figures/logo.png" width="100" />](https://shikokuchuo.net/mirai/articles/shiny.html)
[<img alt="Plumber" src="https://rstudio.github.io/cheatsheets/html/images/logo-plumber.png" width="100" />](https://shikokuchuo.net/mirai/articles/plumber.html) Async backend (supports Shiny ExtendedTask)

[<img alt="Arrow" src="https://arrow.apache.org/img/arrow-logo_hex_black-txt_white-bg.png" width="100" />](https://shikokuchuo.net/mirai/articles/databases.html) &nbsp; Host ADBC database connections

[<img alt="torch" src="https://torch.mlverse.org/css/images/hex/torch.png" width="100" />](https://shikokuchuo.net/mirai/articles/torch.html) &nbsp; Seamless handling of Torch tensors

# `crew`: an encapsulation of `mirai`

## Motivation for `crew`

<center>
<img src="./images/targets.png" width=200>
</center>

::: {.nonincremental style="font-size: 85%;"}

* `targets` is a pipeline tool for reproducible computation at scale in R
* Manages large workflows in statistics and data science:
    * Bayesian data analysis
    * Machine learning
    * Simulation of clinical trials
    * Genomic data analysis

:::

## Challenges

<center>
<img src="./images/targets.png" width=200>
</center>

::: {.nonincremental style="font-size: 85%;"}

1. Scale out parallel workers to meet demand
2. Scale in parallel workers to conserve resources
3. Tailor itself to arbitrary distributed computing environments

:::

## A `targets` pipeline

![](./images/autoscale1.png)

## A worker is an R process that runs tasks

![](./images/autoscale2.png)

## Add workers to meet demand

![](./images/autoscale3.png)

## Reuse workers for subsequent tasks

![](./images/autoscale4.png)


## Discard workers no longer needed

![](./images/autoscale5.png)

## Beginnings: `mirai` and `crew`

<center>
<img src="./images/crew-core.png" width=300>
</center>

::: {style="font-size:85%"}

* `crew` needed a backend to communicate with parallel workers over a local network connection
* Originally considered Redis, but `mirai` is ideal:
    * Does not depend on Redis server
    * Can send larger data objects over the network
* `crew` began using `mirai` in February 2023

:::

## How `mirai` supports `crew`

<center>
<img src="./images/crew-core.png" width=300>
</center>

::: {style="font-size:85%"}

* `crew` launches workers, `mirai` sends tasks to workers
* `mirai` supports modular building blocks for `crew`:
   * **`mirai::daemon(url = "...")`: turn any R process into a worker on the network.**
   * `mirai::saisei()`: rotates websocket connections
   * Down-scaling workers: maximum idle time, maximum number of tasks

:::

## Moju Kapu design of `crew`

<center>
<img src="./images/crew-core.png" width=300>
</center>

* **Encapsulation**: centralized `R6` "controller" interface
* **Modularity**: plugins for different computing environments

## Encapsulation: `R6` classes to wrap `mirai`

:::: {.columns  style="font-size: 90%;"}

::: {.column width="45%"}

<br>

<center>
<img src="./images/crew-design.png" width=400>
</center>

:::

::: {.column width="55%"}

<br>

```{r, eval = FALSE, echo = TRUE}
# Start a new controller.
x <- crew::crew_controller_local(
  workers = 10,
  seconds_idle = 30
)

# Submit many parallel tasks.
x$walk(
  rnorm(1, x),
  iterate = list(x = seq_len(1000))
)

# Optional: wait for all tasks.
x$wait(mode = "all")

# Collect results so far.
str(unlist(x$collect()$result))
#> num [1:1000] 3.2 4.1 2.31 ...
```

:::

::::


## Modularity: `crew` plugins

:::: {.columns  style="font-size: 70%;"}

::: {.column width="50%"}


<center>
<img src="./images/crew.png" width=150>
</center>

```{r, echo = TRUE, eval = FALSE}
crew_controller_local()
```

<br>

<center>
<img src="./images/crew.cluster.png" width=150>
</center>

```{r, echo = TRUE, eval = FALSE}
crew_controller_slurm(
  slurm_memory_gigabytes_per_cpu = 16,
  script_lines = "module load R/4.4.0"
)
```

:::

::: {.column width="50%"}

<center>
<img src="./images/crew.aws.batch.png" width=150>
</center>

```{r, echo = TRUE, eval = FALSE}
crew_controller_aws_batch(
  aws_batch_job_definition = "your_def",
  aws_batch_job_queue = "your_queue"
)
```

<center>
<img src="./images/hex-custom.png" width=150>
</center>

```{r, echo = TRUE, eval = FALSE}
your_custom_controller(...)
```

:::

::::

## Users can write `crew` plugins

::: {.nonincremental}

```{r, echo = TRUE, eval = FALSE}
custom_launcher_class <- R6::R6Class(
  classname = "custom_launcher_class",
  inherit = crew::crew_class_launcher,
  public = list(
    launch_worker = function(call, name, launcher, worker, instance) {

      # 1. Reserve compute for R to run, e.g. start a job on a cluster.
      # 2. Make that job start an R process.
      # 3. Make that R process run the code in `call`.

    },
    terminate_worker = function(handle) {

      # Terminate a worker.

    }
  )
)
```

* How to write a `crew` plugin: <br />
<https://wlandau.github.io/crew/articles/plugins.html>

:::

## `targets` accepts any `crew` controller

::: {.nonincremental}

:::: {.columns}

::: {.column width="20%"}

<center>
<img src="./images/targets.png">
</center>

:::

::: {.column width="80%"}


<center>
<img src="./images/graph.png">
</center>

:::

::::

```{r, eval = FALSE, echo = TRUE}
tar_option_set(
  controller = crew_controller_aws_batch(
    workers = 3,
    seconds_idle = 60,
    aws_batch_job_definition = "your_def",
    aws_batch_job_queue = "your_queue",
    aws_batch_region = "us-east-2"
  )
)
```

* <https://books.ropensci.org/targets/crew.html>

:::

# Thank you

## {.center}

:::: {.columns}
::: {.column width="50%"}

<img alt="mirai logo" src="images/mirai.png" width="120" />
The Shinkansen of parallel computing

<img alt="crew logo" src="images/crew.png" width="120" />
Bringing mirai to distributed data science workloads


:::

::: {.column width="50%"}

The obvious choice for long-distance travel...

<img src="images/shinkansen.png" />

get to your destination faster!
:::

::::

# Appendix: Supporting Slides

## mirai - 100x Faster

Benchmarking:

```{.r}
library(mirai)
daemons(6)
#> [1] 6

library(future)
plan("multisession", workers = 6)

mirai(1)[]
#> [1] 1
value(future(1))
#> [1] 1

bench::mark(mirai(1)[], value(future(1)), relative = TRUE)
#> # A tibble: 2 × 6
#>   expression         min median `itr/sec` mem_alloc `gc/sec`
#>   <bch:expr>       <dbl>  <dbl>     <dbl>     <dbl>    <dbl>
#> 1 mirai(1)[]          1      1       148.        1       NaN
#> 2 value(future(1))  186.   159.        1       152.      Inf
```

<sup>Created on 2024-06-27 with [reprex v2.1.0](https://reprex.tidyverse.org)</sup>

## mirai - WYSIWYG Concept

Production usage requires 'correctness' over 'convenience'

Compare and contrast:

:::: {.columns}
::: {.column width="50%"}

``` r
library(mirai)

res <- list(model = double(1e8),
            acc = 0.95)

m <- mirai(2 * x, x = res$acc)
m[]
#> [1] 1.9
```
:::

::: {.column width="50%"}

``` r
library(future)

res <- list(model = double(1e8),
            acc = 0.95)

f <- future(2 * res$acc)
#> Error in getGlobalsAndPackages(
#> expr, envir = envir, tweak =
#> tweakExpression, : The total
#> size of the 1 globals exported
#> for future expression ('2 *
#> res$acc') is 762.94 MiB.. This
#> exceeds the maximum allowed
#> size of 500.00 MiB (option
#> 'future.globals.maxSize').
#> There is one global: 'res'
#> (762.94 MiB of class 'list')
```

:::
::::

## mirai - One Million Promises

```{.r}
library(mirai)
daemons(8, dispatcher = FALSE)
#> [1] 8

r <- 0
start <- Sys.time()
m <- mirai_map(1:1000000, \(x) x, .promise = \(x) r <<- r + x)
Sys.time() - start
#> Time difference of 6.14953 mins

later::run_now()
r
#> [1] 500000500000
```

<sup>Created on 2024-06-27 with [reprex v2.1.0](https://reprex.tidyverse.org) <br />
Running on an Intel i7 Gen 11 notebook with 16GB RAM.</sup>
